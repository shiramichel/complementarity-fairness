{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard approach (de-identified experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_net_rej(nn.Module):\n",
    "    '''\n",
    "   (Mozannar & Sontag) Linear classifier and deferral for L_CE loss for binary response\n",
    "   novel convex consistent surrogate loss\n",
    "    '''\n",
    "    def __init__(self, input_dim, out_dim):\n",
    "        super(Linear_net_rej, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc = nn.Linear(input_dim, out_dim+1) # out: 0,1,2\n",
    "        self.fc_rej = nn.Linear(input_dim, 1)\n",
    "        torch.nn.init.ones_(self.fc.weight)\n",
    "        torch.nn.init.ones_(self.fc_rej.weight)\n",
    "        self.softmax = nn.Softmax(dim=0) # dim = 0 to get 0,1,2 as output\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        rej = self.fc_rej(x)\n",
    "        #out = torch.cat([out,rej],1)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_CrossEntropyLoss(outputs, h, labels, m, n_classes):\n",
    "    '''\n",
    "    (Mozannar & Sontag) Implmentation of L_{CE}^{\\alpha}\n",
    "        outputs: classifier and rejector model outputs\n",
    "        h: cost of deferring to expert cost of classifier predicting (I_{m =y})\n",
    "        labels: target\n",
    "        m: cost of classifier predicting (alpha* I_{m\\neq y} + I_{m =y})\n",
    "        n_classes: number of classes\n",
    "    '''    \n",
    "    batch_size = outputs.size()[0]            # batch_size\n",
    "    rc = torch.tensor([n_classes] * batch_size, dtype=torch.long)\n",
    "    #labels = torch.tensor(labels, dtype=torch.long)\n",
    "    labels = labels.clone().detach().long()\n",
    "    outputs =  -h*torch.log2( outputs[range(batch_size), rc]) - m*torch.log2(outputs[range(batch_size), labels])   # pick the values corresponding to the labels\n",
    "    return torch.sum(outputs)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier_rej(model, exp_heuristic, data_x, data_y, alpha, p, k):\n",
    "    '''\n",
    "    (Mozannar & Sontag) training script for L_{CE}\n",
    "        model: classifier and rejector model\n",
    "        data_x: input\n",
    "        data_y: label\n",
    "        alpha: hyperparam alpha for loss L_CE^{\\alpha}\n",
    "        p: probability of randomly selecting expert 1\n",
    "    '''\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.5, 0.99), weight_decay=1)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(data_x)*100)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=3.0)\n",
    "\n",
    "    for epoch in range(1):  # loop over the dataset multiple times\n",
    "        inputs = torch.tensor(data_x)\n",
    "        labels = torch.tensor(data_y)\n",
    "\n",
    "        # split to create batch size\n",
    "        x_batches = torch.split(inputs, 5)\n",
    "        y_batches = torch.split(labels, 5) \n",
    "\n",
    "        loss_train = []\n",
    "\n",
    "        model_predictions = 0\n",
    "        expert_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "\n",
    "        for inputs, labels in zip(x_batches, y_batches):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            rand_exp = random.choices([1, k], weights=[p, 1-p])[0] # randomly select expert k\n",
    "\n",
    "            predicted = torch.tensor(exp_heuristic[rand_exp-1](inputs))  # get predictions from selected expert\n",
    "            \n",
    "            h = (predicted==labels)*1\n",
    "            m = [0] * len(inputs) \n",
    "            for j in range (0,len(inputs)): # determines weights\n",
    "                if h[j]:\n",
    "                    m[j] = alpha\n",
    "                    expert_predictions += 1\n",
    "                else:\n",
    "                    m[j] = 1\n",
    "\n",
    "            h = h.clone().detach()\n",
    "            m = torch.tensor(m)\n",
    "            inputs = inputs.to(model.fc.weight.dtype)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Loss\n",
    "            loss = reject_CrossEntropyLoss(outputs, h, labels, m, 2) # this is loss for classifier and rejector\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            loss_train.append(loss.item())\n",
    "\n",
    "\n",
    "            # Training accuracy\n",
    "            model_predictions += torch.sum((torch.argmax(outputs, dim=1) == labels).float()).item()\n",
    "            expert_predictions += torch.sum((torch.argmax(predicted) == labels).float()).item()\n",
    "            total_samples += len(labels)\n",
    "            #model_accuracy = model_predictions / total_samples\n",
    "            #expert_accuracy = expert_predictions / total_samples\n",
    "\n",
    "    #print('Model Training Accuracy: ', model_accuracy)\n",
    "    #print('Overall Expert Training Accuracy:', expert_accuracy)\n",
    "\n",
    "    plt.plot(loss_train, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        \n",
    "            #print(\"loss \" + str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier_rej(model, exp_heuristic, data_x, data_y, p, k, exp_instances):\n",
    "    '''\n",
    "    (Mozannar & Sontag) Test classifier and deferral model for L_{CE} loss\n",
    "    '''\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = [0]*k\n",
    "    exp_total = [0]*k\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    points = len(data_x)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(data_x)\n",
    "        labels = torch.tensor(data_y)\n",
    "\n",
    "        inputs = inputs.to(model.fc.weight.dtype)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1) #0/1 (ML), 2 (defer to expert)\n",
    "        predicted_exp = [torch.tensor(exp_heuristic(inputs)) for exp_heuristic in exp_heuristic]\n",
    "\n",
    "        for i in range(len(inputs)):\n",
    "            r = (predicted[i] == 2).item() # if 2, then defer to expert\n",
    "            if r:\n",
    "                rand_exp = random.choices([1, k], weights=[p, 1-p])[0] # randomly select expert for each point\n",
    "                correct_sys += (predicted_exp[rand_exp-1][i] == labels[i]).item()\n",
    "                exp[rand_exp-1] += (predicted_exp[rand_exp-1][i] == labels[i]).item()\n",
    "                exp_total[rand_exp-1] += 1\n",
    "                exp_instances[rand_exp-1].append(i)\n",
    "            else: \n",
    "                correct += (predicted[i] == labels[i]).item()\n",
    "                correct_sys += (predicted[i] == labels[i]).item()\n",
    "                total += 1\n",
    "        real_total += labels.size(0)\n",
    "\n",
    "    print(\"system accuracy\", 100 * correct_sys / real_total)\n",
    "    print(\"total points:\", points)\n",
    "    print()\n",
    "\n",
    "    for idx, (c, expert_total) in enumerate(zip(exp, exp_total)):\n",
    "        print(f\"Expert {idx+1} defer count:\", expert_total)\n",
    "        print(f\"Expert {idx+1} defer percent:\", 100 * expert_total / points if expert_total != 0 else 0)\n",
    "        print(f\"Expert {idx+1} correct predictions:\", c)\n",
    "        print(f\"Expert {idx+1} accuracy:\", 100 * c / (expert_total + 0.0002) if expert_total != 0 else 0)\n",
    "        print()\n",
    "\n",
    "    print(\"Not deferred to any expert count:\", total)\n",
    "    print(\"Not deferred percent:\", 100 * total / points)\n",
    "    print(\"Model correct predictions:\", correct)\n",
    "    print(\"Model accuracy:\", 100 * correct / (total + 0.0001))\n",
    "    print()\n",
    "\n",
    "    #ratios = [exp_total / exp_correct if exp_correct != 0 else 0 for exp_total, exp_correct in zip(exp_total, exp)]\n",
    "    #for idx, ratio in enumerate(ratios):\n",
    "        #print(f\"Expert {idx+1} to other experts ratio:\", ratio)\n",
    "\n",
    "    print()\n",
    "    overall_exp_total = sum(exp_total)\n",
    "    overall_exp_correct = sum(exp)\n",
    "    print(\"Overall expert count:\", overall_exp_total)\n",
    "    print(\"Overall expert defer percent:\", 100 * overall_exp_total / points)\n",
    "    print(\"Overall expert correct predictions:\", overall_exp_correct)\n",
    "    print(\"Overall expert accuracy:\", 100 * overall_exp_correct / (overall_exp_total + 0.0001) if overall_exp_total != 0 else 0)\n",
    "\n",
    "    return exp_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal approach (identified experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_net_rej_id(nn.Module):\n",
    "    '''\n",
    "   (Mozannar & Sontag) Linear classifier and deferral for L_CE loss for binary response\n",
    "   novel convex consistent surrogate loss\n",
    "    '''\n",
    "    def __init__(self, input_dim, out_dim, k):\n",
    "        super(Linear_net_rej_id, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc = nn.Linear(input_dim, out_dim+k) # out: 0,1,2,3\n",
    "        self.fc_rej = nn.Linear(input_dim, 1)\n",
    "        torch.nn.init.ones_(self.fc.weight)\n",
    "        torch.nn.init.ones_(self.fc_rej.weight)\n",
    "        self.softmax = nn.Softmax(dim=0) # dim = 0 to get 0,1,2,3 as output\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        rej = self.fc_rej(x)\n",
    "        #out = torch.cat([out,rej],1)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_CrossEntropyLoss_id(outputs, h, labels, m, n_classes):\n",
    "    '''\n",
    "    (Mozannar & Sontag) Implmentation of L_{CE}^{\\alpha}\n",
    "        outputs: classifier and rejector model outputs\n",
    "        h: cost of deferring to expert k cost of classifier predicting (I_{m =y})\n",
    "        labels: target\n",
    "        m: cost of classifier predicting (alpha* I_{m\\neq y} + I_{m =y})\n",
    "        n_classes: number of classes, binary here\n",
    "    '''    \n",
    "    batch_size = outputs.size()[0]            # batch_size\n",
    "    rc = torch.tensor([n_classes] * batch_size, dtype=torch.long)\n",
    "    labels = labels.clone().detach().long()\n",
    "    outputs_exp = [torch.zeros(batch_size) for _ in range(k)]\n",
    "\n",
    "    for i in range(k):\n",
    "        outputs_exp[i] = -h[i] * torch.log2(outputs[range(batch_size), rc]) - m[:, i] * torch.log2(outputs[range(batch_size), labels])\n",
    "\n",
    "    outputs = sum(outputs_exp)  # Sum the losses from all experts\n",
    "    \n",
    "    return torch.sum(outputs) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier_rej_id(model, exp_heuristic, data_x, data_y, alpha, k):\n",
    "    '''\n",
    "    (Mozannar & Sontag) training script for L_{CE}\n",
    "        model: classifier and rejector model\n",
    "        data_x: input\n",
    "        data_y: label\n",
    "        alpha: expert 1 hyperparam alpha for loss L_CE^{\\alpha} \n",
    "        beta: expert 2 hyperparam alpha for loss L_CE^{\\beta} \n",
    "        p: probability of randomly selecting expert 1\n",
    "    '''\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.08, betas = (0.75, .1), weight_decay=.2)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(data_x)*100)\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=3.0)\n",
    "\n",
    "    for epoch in range(1):  # loop over the dataset multiple times\n",
    "        inputs = torch.tensor(data_x)\n",
    "        labels = torch.tensor(data_y)\n",
    "\n",
    "        # split to create batch size\n",
    "        x_batches = torch.split(inputs, 5)\n",
    "        y_batches = torch.split(labels, 5) \n",
    "\n",
    "        loss_train = []\n",
    "\n",
    "        for inputs, labels in zip(x_batches, y_batches):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predicted = [torch.tensor(expert(inputs)) for expert in exp_heuristic]\n",
    "\n",
    "            h_list = [(expert_output == labels) * 1 for expert_output in predicted]\n",
    "\n",
    "            m = torch.zeros(len(inputs), k)\n",
    "\n",
    "            for j in range(len(inputs)):\n",
    "                for i in range(k):\n",
    "                    if h_list[i][j]:\n",
    "                        m[j][i] = alpha\n",
    "                    else:\n",
    "                        m[j][i] = 1\n",
    "\n",
    "            h_list = [h.clone().detach() for h in h_list]\n",
    "            m = m.clone().detach()\n",
    "\n",
    "            inputs = inputs.to(model.fc.weight.dtype)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Loss computation\n",
    "            loss = reject_CrossEntropyLoss_id(outputs, h_list, labels, m, 2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            loss_train.append(loss.item())\n",
    "\n",
    "    plt.plot(loss_train, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier_rej_id(model, exp_heuristic, data_x, data_y, k, exp_instances):\n",
    "    '''\n",
    "    (Mozannar & Sontag) Test classifier and deferral model for L_{CE} loss\n",
    "    '''\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = [0]*k\n",
    "    exp_total = [0]*k\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    points = len(data_x)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(data_x)\n",
    "        labels = torch.tensor(data_y)\n",
    "\n",
    "        inputs = inputs.to(model.fc.weight.dtype)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_exp = [torch.tensor(exp_heuristic(inputs)) for exp_heuristic in exp_heuristic]\n",
    "\n",
    "        for i in range(len(inputs)):\n",
    "            r = predicted[i].item() > 1  # if greater than 1, then defer to experts\n",
    "            if r:\n",
    "                expert_id = predicted[i].item() - 2  # expert index starts from 0\n",
    "                correct_sys += (predicted_exp[expert_id][i] == labels[i]).item()\n",
    "                exp[expert_id] += (predicted_exp[expert_id][i] == labels[i]).item()\n",
    "                exp_total[expert_id] += 1\n",
    "                exp_instances[expert_id].append(i)\n",
    "\n",
    "            else:\n",
    "                correct += (predicted[i] == labels[i]).item()\n",
    "                correct_sys += (predicted[i] == labels[i]).item()\n",
    "                total += 1\n",
    "        real_total += labels.size(0)\n",
    "\n",
    "    print(\"system accuracy\", 100 * correct_sys / real_total)\n",
    "    print(\"total points:\", points)\n",
    "    print()\n",
    "\n",
    "    for idx, (c, expert_total) in enumerate(zip(exp, exp_total)):\n",
    "        print(f\"Expert {idx+1} defer count:\", expert_total)\n",
    "        print(f\"Expert {idx+1} defer percent:\", 100 * expert_total / points if expert_total != 0 else 0)\n",
    "        print(f\"Expert {idx+1} correct predictions:\", c)\n",
    "        print(f\"Expert {idx+1} accuracy:\", 100 * c / (expert_total + 0.0002) if expert_total != 0 else 0)\n",
    "        print()\n",
    "\n",
    "    print(\"Not deferred to any expert count:\", total)\n",
    "    print(\"Not deferred percent:\", 100 * total / points)\n",
    "    print(\"Model correct predictions:\", correct)\n",
    "    print(\"Model accuracy:\", 100 * correct / (total + 0.0001))\n",
    "    print()\n",
    "\n",
    "    #ratios = [exp_total / exp_correct if exp_correct != 0 else 0 for exp_total, exp_correct in zip(exp_total, exp)]\n",
    "    #for idx, ratio in enumerate(ratios):\n",
    "        #print(f\"Expert {idx+1} to other experts ratio:\", ratio)\n",
    "\n",
    "    print()\n",
    "    overall_exp_total = sum(exp_total)\n",
    "    overall_exp_correct = sum(exp)\n",
    "    print(\"Overall expert count:\", overall_exp_total)\n",
    "    print(\"Overall expert defer percent:\", 100 * overall_exp_total / points)\n",
    "    print(\"Overall expert correct predictions:\", overall_exp_correct)\n",
    "    print(\"Overall expert accuracy:\", 100 * overall_exp_correct / (overall_exp_total + 0.0001) if overall_exp_total != 0 else 0)\n",
    "\n",
    "    return exp_instances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- different types of experts\n",
    "    1. manually create heuristics\n",
    "    2. experts as non-linear classifiers (decision tree classifiers)\n",
    "    3. based on covariance instead of labels \n",
    "<br>\n",
    "<br>\n",
    "- different types of datasets\n",
    "    1. complex, non-linearly separable (3 blobs)\n",
    "<br>\n",
    "<br>\n",
    "- semi-synthetic setting\n",
    "    1. hate speech detection: https://github.com/t-davidson/hate-speech-and-offensive-language\n",
    "    2. fact-checking (Christo)\n",
    "    3. CheXpert: https://stanfordmlgroup.github.io/competitions/chexpert/\n",
    "    4. multi-label datasets for semantic scene and text classification: https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html\n",
    "<br>\n",
    "<br>\n",
    "- alternative method\n",
    "    1. majority vote? \n",
    "    2. hierarchical (highest rank/authority)\n",
    "    3. panel of very similar views/knowledges\n",
    "    4. more representative group (different views/knowledge sand various ranks/authority)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, stratify=y, random_state=456)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Standard approach\n",
    "\n",
    "experts = [expert1, expert2]\n",
    "k = len(experts)\n",
    "m = Linear_net_rej(2,k) # 2 inputs\n",
    "alpha = 0\n",
    "p = 0.5\n",
    "\n",
    "run_classifier_rej(m, experts, X_train, y_train, alpha, p, k)\n",
    "\n",
    "# keep track of what in/correct instances are deferred to each expert by index and inputs\n",
    "exp_index = [[] for _ in range(k)]\n",
    "\n",
    "exp1_index, exp2_index = test_classifier_rej(m, experts, X_test, y_test, p, k, exp_index)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Optimal approach\n",
    "\n",
    "m = Linear_net_rej_id(2, 2, k) # 2 inputs\n",
    "alpha = 0\n",
    "\n",
    "run_classifier_rej_id(m, experts, X_train, y_train, alpha, k)\n",
    "\n",
    "# keep track of what in/correct instances are deferred to each expert by index and inputs\n",
    "exp_index = [[] for _ in range(k)]\n",
    "\n",
    "exp1_index, exp2_index = test_classifier_rej_id(m, experts, X_test, y_test, k, exp_index)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
