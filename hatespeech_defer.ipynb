{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT --- Vijay Keswani Note: This notebook is from the code of Mozannar, Sontag 2020. I use this notebook only to extract the cleaned dataset and save it as an npy file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fqpaVy5IRwJM"
   },
   "source": [
    "# Hate Speech and Offensive Language Detection\n",
    "This notebook runs our experiments on the Hate Speech and Offensive Language Detection tweet dataset.\n",
    "WARNING: dataset contains offensive language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmjrIyVlbO44"
   },
   "source": [
    "##  AAE detection model\n",
    "As described in our paper, we use the model from https://github.com/slanglab/twitteraae to detect the dialect of each tweet, we only need the model files from the repo which we have conveniently copied in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import sys,os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import time\n",
    "import random\n",
    "vocabfile = \"twitteraae_models/model_vocab.txt\" # change path if needed, path inside twitteraae repo is twitteraae/model/model_vocab.txt\n",
    "modelfile = \"twitteraae_models/model_count_table.txt\" # change path if needed, path inside twitteraae repo is twitteraae/model/model_vocab.txt\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "Uk4UtaGhbbxt",
    "outputId": "87575ecf-058f-4db2-ac66-5781ed095e98"
   },
   "outputs": [],
   "source": [
    "# the following functions are copied from twitteraae for convenience\n",
    "K=0; wordprobs=None; w2num=None\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Idempotent\"\"\"\n",
    "    global vocab,w2num,N_wk,N_k,wordprobs,N_w,K, modelfile,vocabfile\n",
    "    if wordprobs is not None:\n",
    "        # assume already loaded\n",
    "        return\n",
    "\n",
    "    N_wk = np.loadtxt(modelfile)\n",
    "    N_w = N_wk.sum(1)\n",
    "    N_k = N_wk.sum(0)\n",
    "    K = len(N_k)\n",
    "    wordprobs = (N_wk + 1) / N_k\n",
    "\n",
    "    vocab = [L.split(\"\\t\")[-1].strip() for L in open(vocabfile,encoding=\"utf8\")]\n",
    "    w2num = {w:i for i,w in enumerate(vocab)}\n",
    "    assert len(vocab) == N_wk.shape[0]\n",
    "\n",
    "def infer_cvb0(invocab_tokens, alpha, numpasses):\n",
    "    global K,wordprobs,w2num\n",
    "    doclen = len(invocab_tokens)\n",
    "\n",
    "    # initialize with likelihoods\n",
    "    Qs = np.zeros((doclen, K))\n",
    "    for i in range(0,doclen):\n",
    "        w = invocab_tokens[i]\n",
    "        Qs[i,:] = wordprobs[w2num[w],:]\n",
    "        Qs[i,:] /= Qs[i,:].sum()\n",
    "    lik = Qs.copy()  # pertoken normalized but proportionally the same for inference\n",
    "\n",
    "    Q_k = Qs.sum(0)\n",
    "    for itr in range(1,numpasses):\n",
    "        # print \"cvb0 iter\", itr\n",
    "        for i in range(0,doclen):\n",
    "            Q_k -= Qs[i,:]\n",
    "            Qs[i,:] = lik[i,:] * (Q_k + alpha)\n",
    "            Qs[i,:] /= Qs[i,:].sum()\n",
    "            Q_k += Qs[i,:]\n",
    "\n",
    "    Q_k /= Q_k.sum()\n",
    "    return Q_k\n",
    "\n",
    "def predict_lang(tokens, alpha=1, numpasses=5, thresh1=1, thresh2=0.2):\n",
    "    invocab_tokens = [w.lower() for w in tokens if w.lower() in w2num]\n",
    "    # check that at least xx tokens are in vocabulary\n",
    "    if len(invocab_tokens) < thresh1:\n",
    "        return None  \n",
    "    # check that at least yy% of tokens are in vocabulary\n",
    "    elif len(invocab_tokens) / len(tokens) < thresh2:\n",
    "        return None\n",
    "    else:\n",
    "        posterior = infer_cvb0(invocab_tokens, alpha=alpha, numpasses=numpasses)\n",
    "        return posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this loads the twitteraae model for detection\n",
    "load_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pKn4AL_cRwJo"
   },
   "source": [
    "We load the dataset 'labeled_data.csv', available at https://github.com/t-davidson/hate-speech-and-offensive-language, for convenience we copy it to this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = nlp\n",
    "url = re.compile('(<url>.*</url>)')\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Juu5hXhbRy7"
   },
   "outputs": [],
   "source": [
    "# for cnn\n",
    "\n",
    "labeled_data_path = \"data/labeled_data.csv\" # change path if needed\n",
    "\n",
    "TEXT = data.Field(tokenize = tokenize_en, batch_first = True)\n",
    "LABEL = data.LabelField(dtype = torch.long)\n",
    "EXPERT = data.LabelField(dtype = torch.long)\n",
    "GROUP = data.LabelField(dtype = torch.long)\n",
    "EXPERTLABEL = data.LabelField(dtype = torch.long)\n",
    "\n",
    "fields = [(None, None),(None, None),('expertlabel', EXPERTLABEL),('group', GROUP),('expert', EXPERT),\n",
    "          ('label', LABEL), ('text', TEXT)]\n",
    "\n",
    "train_data_orig = data.TabularDataset.splits(\n",
    "                                        path = '',\n",
    "                                        train = labeled_data_path,\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cf20Ut32oPCd"
   },
   "source": [
    "Augment data with expert predictions and demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "pYfTDftioZBu",
    "outputId": "8e991090-054a-440a-ef1c-21d98b3996fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error processing tweet: ['@Fulf_ShawnFulf', 'peckerwood']\n",
      "error processing tweet: ['GA', 'Charlie', '@Charlie4927', '@sholzbee', '@DorisTafoya1', '@cat_lmbo', '@Jagauress', '@Walter_lars', '@lynnemrnp', '@AmyMek', '@Justin_Awe']\n",
      "error processing tweet: ['RT', '@cenopant', ':', '(', 'she)s', '\\n', 'bro(was)ken', '\\n', 'bec(a)use', '\\n', 's(side)he', '\\n', 'beli(hoe)ved']\n"
     ]
    }
   ],
   "source": [
    "# build expert data\n",
    "all_data = train_data_orig[0]\n",
    "\n",
    "p = 0.75 # expert probability of being correct for AA tweeet\n",
    "q = 0.9 # expert probability of being correct for AA tweeet\n",
    "\n",
    "# tracker variables for statistics\n",
    "sum = 0\n",
    "total = 0\n",
    "i = 0\n",
    "aa_frac = 0\n",
    "for example in all_data:\n",
    "    lang = predict_lang(vars(example)['text'])\n",
    "    aa = 0\n",
    "    try:\n",
    "        if lang[0] >= 0.5:\n",
    "            aa = 1\n",
    "    except:\n",
    "        print(\"error processing tweet: \"+str(vars(example)['text']))\n",
    "    label = vars(example)['label']\n",
    "    exp = 0 # 0: expert wrong, 1: expert is right\n",
    "    exp_label = 0\n",
    "    if aa == 1: # if tweet is african american\n",
    "\n",
    "        coin = np.random.binomial(1,p)\n",
    "        if coin:\n",
    "            exp =1 \n",
    "            exp_label = np.longlong(label)\n",
    "        else:\n",
    "            exp_label = np.longlong(np.argmax(np.random.multinomial(1,[1/3]*3 , size=1)))\n",
    "            exp =0\n",
    "    else:\n",
    "        coin = np.random.binomial(1,q)\n",
    "        if coin:\n",
    "            exp =1 # is right 90% of time\n",
    "            exp_label = np.longlong(label)\n",
    "        else:\n",
    "            exp_label = np.longlong(np.argmax(np.random.multinomial(1,[1/3]*3 , size=1)))\n",
    "            exp =0\n",
    "    #if label =='2' : # 2: neither, 1: offensive, 0: hate speech\n",
    "    #    aa = 1\n",
    "    vars(all_data[i])['expertlabel'] = exp_label\n",
    "    vars(all_data[i])['group'] = str(aa)\n",
    "    vars(all_data[i])['expert'] = exp\n",
    "    aa_frac += aa\n",
    "    i += 1\n",
    "    total +=1\n",
    "    sum += exp\n",
    "#print(sum/total)\n",
    "#print(aa_frac/total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build data for Pytorch and vectorize, this requires the glove.6b.100d embeddings which will be downloaded (862mb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:58, 4.83MB/s]                             \n",
      "100%|███████████████████████████████▉| 399999/400000 [00:06<00:00, 61883.93it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LABEL.build_vocab(all_data)\n",
    "EXPERT.build_vocab(all_data)\n",
    "GROUP.build_vocab(all_data)\n",
    "EXPERTLABEL.build_vocab(all_data)\n",
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(all_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24783\n"
     ]
    }
   ],
   "source": [
    "print (len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26954"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "with open(\"data/labeled_data.csv\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts, labels, groups = [], [], []\n",
    "for i in range(len(all_data)):\n",
    "    posts.append(vars(all_data[i])['text'])\n",
    "    labels.append(vars(all_data[i])['label'])\n",
    "    groups.append(vars(all_data[i])['group'])\n",
    "    \n",
    "len(posts), len(groups), len(labels)\n",
    "\n",
    "labelled_data = {\"posts\": posts, \"labels\": labels, \"groups\": groups}\n",
    "np.save('output/labelled_data.npy', labelled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data for train, test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLKxaqpIRwJ4"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_data, test_data, valid_data  = all_data.split(split_ratio=[0.6,0.1,0.3])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    sort = False,\n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is of two parts:\n",
    "1) the first part goes through our method and baselines to get results\n",
    "2) the second combines all models to get std and confidence intervals, but need to go through the first part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZLZocE7ggnm"
   },
   "source": [
    "# Build model\n",
    "Model definitions for sentiment analysis adapted from https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/3%20-%20Faster%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMT9UoiigZhS"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.conv_0 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[0], embedding_dim))\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[1], embedding_dim))\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(in_channels = 1, \n",
    "                                out_channels = n_filters, \n",
    "                                kernel_size = (filter_sizes[2], embedding_dim))\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
    "        conved_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
    "        conved_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        \n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat((pooled_0, pooled_1, pooled_2), dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        out = self.fc(cat)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "class CNN_rej(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.embedding_rej = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs_rej = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc_rej = nn.Linear(len(filter_sizes) * n_filters, 1)\n",
    "        \n",
    "        self.dropout_rej = nn.Dropout(dropout)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        embedded_rej = self.embedding_rej(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded_rej = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved_rej = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs_rej]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled_rej = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat_rej = self.dropout_rej(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        out_rej = self.fc_rej(cat_rej)\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        out = self.fc(cat)\n",
    "        out =  torch.cat((out, out_rej), 1)\n",
    "\n",
    "        out = self.softmax(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100 # fixed\n",
    "N_FILTERS = 300 # hyperparameterr\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 4\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "#model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "model = CNN_rej(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 3, DROPOUT, PAD_IDX)\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hs2N0LRbRwKb"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VHXr-a2ARwKf"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "usU7JU75RwKp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    correct = max_preds.squeeze(1).eq(y)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]])\n",
    "def reject_CrossEntropyLoss(outputs, m, labels, m2, n_classes):\n",
    "    '''\n",
    "    The L_{CE} loss implementation for hatespeech, identical to CIFAR implementation\n",
    "    ----\n",
    "    outputs: network outputs\n",
    "    m: cost of deferring to expert cost of classifier predicting (alpha* I_{m\\neq y} + I_{m =y})\n",
    "    labels: target\n",
    "    m2:  cost of classifier predicting (alpha* I_{m\\neq y} + I_{m =y})\n",
    "    n_classes: number of classes\n",
    "    '''\n",
    "    batch_size = outputs.size()[0]            # batch_size\n",
    "    rc = [n_classes] * batch_size\n",
    "    rc = torch.tensor(rc)\n",
    "    outputs =  -m*torch.log2( outputs[range(batch_size), rc]) - m2*torch.log2(outputs[range(batch_size), labels])   # pick the values corresponding to the labels\n",
    "    return torch.sum(outputs)/batch_size\n",
    "\n",
    "def train_reject(model, iterator, optimizer,alpha):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text)\n",
    "        batch_size = predictions.size()[0]\n",
    "        # get expert predictions and costs \n",
    "        m = (1 - batch.expert)*1.0\n",
    "        m2 = [1] * batch_size\n",
    "        m2 = torch.tensor(m2)\n",
    "        for j in range (0,batch_size):\n",
    "            exp = m[j].item()\n",
    "            if exp:\n",
    "                m2[j] = alpha\n",
    "            else:\n",
    "                m2[j] = 1\n",
    "\n",
    "        m2 = m2.to(device)\n",
    "\n",
    "        loss = reject_CrossEntropyLoss(predictions, m, batch.label, m2, 3)\n",
    "\n",
    "        acc = categorical_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "def evaluate_reject(model, iterator):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text)\n",
    "            batch_size = predictions.size()[0]            # batch_size\n",
    "            m = 1 - batch.expert\n",
    "            m2 = [1] * batch_size\n",
    "            m2 = torch.tensor(m2)\n",
    "            m2 = m2.to(device)\n",
    "            loss = reject_CrossEntropyLoss(predictions, m, batch.label, m2, 3)\n",
    "            acc = categorical_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbfpfCHA0UNe"
   },
   "outputs": [],
   "source": [
    "def metrics_print(net, loader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs = net(data.text)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            batch_size = outputs.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = (predicted[i].item() == 3)\n",
    "                if r==0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == data.label[i]).item()\n",
    "                    correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                if r==1:\n",
    "                    exp += 1 - data.expert[i].item()\n",
    "                    correct_sys += 1 - data.expert[i].item()\n",
    "                    exp_total+=1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    print(to_print)\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "def metrics_print_fairness(net, loader):\n",
    "    net.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs = net(data.text)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            batch_size = outputs.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = (predicted[i].item() == 3)\n",
    "                prediction = 0\n",
    "                if r==0:\n",
    "                    prediction = predicted[i]\n",
    "                if r==1:\n",
    "                    prediction = data.expertlabel[i].item()\n",
    "\n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvNc3f0YRwK-"
   },
   "source": [
    "Train the model by validation over alpha in [0,1] with steps of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "colab_type": "code",
    "id": "IapphlTjRwLD",
    "outputId": "66727958-0c5a-4f5d-e9ed-d16dc76cec25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michel.sh/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': '0 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.41403685116732, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '152 out of2478', 'system accuracy': 84.34221146085552, 'expert accuracy': 83.74891799235444, 'classifier accuracy': 93.42099117040054, 'alone classifier': 0.0}\n",
      "{'coverage': '42 out of2478', 'system accuracy': 83.85794995964487, 'expert accuracy': 83.62068278976332, 'classifier accuracy': 97.61881519329715, 'alone classifier': 0.0}\n",
      "{'coverage': '61 out of2478', 'system accuracy': 83.69652945924132, 'expert accuracy': 83.40917803813173, 'classifier accuracy': 95.08181134129288, 'alone classifier': 0.0}\n",
      "{'coverage': '57 out of2478', 'system accuracy': 83.89830508474576, 'expert accuracy': 83.60181052442705, 'classifier accuracy': 96.49105878761615, 'alone classifier': 0.0}\n",
      "{'coverage': '152 out of2478', 'system accuracy': 84.34221146085552, 'expert accuracy': 83.74891799235444, 'classifier accuracy': 93.42099117040054, 'alone classifier': 0.0}\n",
      "[6.133979015334948, 84.34221146085552, 83.74891799235444, 93.42099117040054]\n",
      "{'coverage': '0 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.41403685116732, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '3 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.39393265503574, 'classifier accuracy': 99.99666677777407, 'alone classifier': 0.0}\n",
      "{'coverage': '71 out of2478', 'system accuracy': 83.97901533494753, 'expert accuracy': 83.71416005698711, 'classifier accuracy': 92.95761555265415, 'alone classifier': 0.0}\n",
      "{'coverage': '30 out of2478', 'system accuracy': 83.49475383373688, 'expert accuracy': 83.37417619492025, 'classifier accuracy': 93.33302222325926, 'alone classifier': 0.0}\n",
      "{'coverage': '147 out of2478', 'system accuracy': 84.1000807102502, 'expert accuracy': 83.52637635981327, 'classifier accuracy': 93.19721551209828, 'alone classifier': 0.0}\n",
      "{'coverage': '147 out of2478', 'system accuracy': 84.1000807102502, 'expert accuracy': 83.52637635981327, 'classifier accuracy': 93.19721551209828, 'alone classifier': 0.0}\n",
      "[5.932203389830509, 84.1000807102502, 83.52637635981327, 93.19721551209828]\n",
      "{'coverage': '0 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.41403685116732, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '26 out of2478', 'system accuracy': 83.65617433414043, 'expert accuracy': 83.56443037810519, 'classifier accuracy': 92.30733727947201, 'alone classifier': 0.0}\n",
      "{'coverage': '10 out of2478', 'system accuracy': 83.53510895883777, 'expert accuracy': 83.46838869786153, 'classifier accuracy': 99.9990000099999, 'alone classifier': 0.0}\n",
      "{'coverage': '124 out of2478', 'system accuracy': 84.01937046004842, 'expert accuracy': 83.55989094648335, 'classifier accuracy': 92.74186069204782, 'alone classifier': 0.0}\n",
      "{'coverage': '86 out of2478', 'system accuracy': 83.7368845843422, 'expert accuracy': 83.48661509309238, 'classifier accuracy': 90.69756895631517, 'alone classifier': 0.0}\n",
      "{'coverage': '124 out of2478', 'system accuracy': 84.01937046004842, 'expert accuracy': 83.55989094648335, 'classifier accuracy': 92.74186069204782, 'alone classifier': 0.0}\n",
      "[5.004035512510089, 84.01937046004842, 83.55989094648335, 92.74186069204782]\n",
      "{'coverage': '0 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.41403685116732, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '31 out of2478', 'system accuracy': 83.69652945924132, 'expert accuracy': 83.61258000714507, 'classifier accuracy': 90.3222892829378, 'alone classifier': 0.0}\n",
      "{'coverage': '90 out of2478', 'system accuracy': 84.22114608555286, 'expert accuracy': 83.71021074453847, 'classifier accuracy': 97.77766913592318, 'alone classifier': 0.0}\n",
      "{'coverage': '202 out of2478', 'system accuracy': 84.82647296206618, 'expert accuracy': 84.09489594948191, 'classifier accuracy': 93.06926085680155, 'alone classifier': 0.0}\n",
      "{'coverage': '109 out of2478', 'system accuracy': 84.14043583535108, 'expert accuracy': 83.74840998324947, 'classifier accuracy': 92.66046544911427, 'alone classifier': 0.0}\n",
      "{'coverage': '202 out of2478', 'system accuracy': 84.82647296206618, 'expert accuracy': 84.09489594948191, 'classifier accuracy': 93.06926085680155, 'alone classifier': 0.0}\n",
      "[8.151735270379339, 84.82647296206618, 84.09489594948191, 93.06926085680155]\n",
      "{'coverage': '0 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.41403685116732, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '35 out of2478', 'system accuracy': 83.53510895883777, 'expert accuracy': 83.46294854990188, 'classifier accuracy': 88.5711755109271, 'alone classifier': 0.0}\n",
      "{'coverage': '248 out of2478', 'system accuracy': 84.62469733656174, 'expert accuracy': 83.72196558547394, 'classifier accuracy': 92.74189808794432, 'alone classifier': 0.0}\n",
      "{'coverage': '133 out of2478', 'system accuracy': 84.62469733656174, 'expert accuracy': 84.05116553934623, 'classifier accuracy': 94.73677087460837, 'alone classifier': 0.0}\n",
      "{'coverage': '88 out of2478', 'system accuracy': 83.7772397094431, 'expert accuracy': 83.51463736279186, 'classifier accuracy': 90.90898760342317, 'alone classifier': 0.0}\n",
      "{'coverage': '133 out of2478', 'system accuracy': 84.62469733656174, 'expert accuracy': 84.05116553934623, 'classifier accuracy': 94.73677087460837, 'alone classifier': 0.0}\n",
      "[5.367231638418079, 84.62469733656174, 84.05116553934623, 94.73677087460837]\n",
      "{'coverage': '1 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.4073408633556, 'classifier accuracy': 99.9900009999, 'alone classifier': 0.0}\n",
      "{'coverage': '4 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.38722042140498, 'classifier accuracy': 99.99750006249845, 'alone classifier': 0.0}\n",
      "{'coverage': '78 out of2478', 'system accuracy': 84.1000807102502, 'expert accuracy': 83.62499303125058, 'classifier accuracy': 98.71782215663826, 'alone classifier': 0.0}\n",
      "{'coverage': '224 out of2478', 'system accuracy': 84.70540758676351, 'expert accuracy': 83.85092423683015, 'classifier accuracy': 93.30352977520992, 'alone classifier': 0.0}\n",
      "{'coverage': '79 out of2478', 'system accuracy': 83.81759483454398, 'expert accuracy': 83.45143114202325, 'classifier accuracy': 94.93658868786241, 'alone classifier': 0.0}\n",
      "{'coverage': '224 out of2478', 'system accuracy': 84.70540758676351, 'expert accuracy': 83.85092423683015, 'classifier accuracy': 93.30352977520992, 'alone classifier': 0.0}\n",
      "[9.03954802259887, 84.70540758676351, 83.85092423683015, 93.30352977520992]\n",
      "{'coverage': '0 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.41403685116732, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '13 out of2478', 'system accuracy': 83.45439870863599, 'expert accuracy': 83.40770114339139, 'classifier accuracy': 92.30698225398267, 'alone classifier': 0.0}\n",
      "{'coverage': '83 out of2478', 'system accuracy': 83.93866020984665, 'expert accuracy': 83.59080721579897, 'classifier accuracy': 93.97579039061398, 'alone classifier': 0.0}\n",
      "{'coverage': '45 out of2478', 'system accuracy': 83.81759483454398, 'expert accuracy': 83.60048634603483, 'classifier accuracy': 95.55534321034841, 'alone classifier': 0.0}\n",
      "{'coverage': '68 out of2478', 'system accuracy': 83.69652945924132, 'expert accuracy': 83.48547025016845, 'classifier accuracy': 91.17633650538748, 'alone classifier': 0.0}\n",
      "{'coverage': '83 out of2478', 'system accuracy': 83.93866020984665, 'expert accuracy': 83.59080721579897, 'classifier accuracy': 93.97579039061398, 'alone classifier': 0.0}\n",
      "[3.3494753833736883, 83.93866020984665, 83.59080721579897, 93.97579039061398]\n",
      "{'coverage': '0 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.41403685116732, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '1 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.4073408633556, 'classifier accuracy': 99.9900009999, 'alone classifier': 0.0}\n",
      "{'coverage': '18 out of2478', 'system accuracy': 83.57546408393866, 'expert accuracy': 83.49592817106276, 'classifier accuracy': 94.44391975600135, 'alone classifier': 0.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': '92 out of2478', 'system accuracy': 83.85794995964487, 'expert accuracy': 83.52891169078696, 'classifier accuracy': 92.39120392260443, 'alone classifier': 0.0}\n",
      "{'coverage': '232 out of2478', 'system accuracy': 84.38256658595641, 'expert accuracy': 83.52626148474965, 'classifier accuracy': 92.67237384811472, 'alone classifier': 0.0}\n",
      "{'coverage': '232 out of2478', 'system accuracy': 84.38256658595641, 'expert accuracy': 83.52626148474965, 'classifier accuracy': 92.67237384811472, 'alone classifier': 0.0}\n",
      "[9.362389023405973, 84.38256658595641, 83.52626148474965, 92.67237384811472]\n",
      "{'coverage': '0 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.41403685116732, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '2 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.40063946683041, 'classifier accuracy': 99.99500024998748, 'alone classifier': 0.0}\n",
      "{'coverage': '7 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.40752056596354, 'classifier accuracy': 85.71306124198226, 'alone classifier': 0.0}\n",
      "{'coverage': '36 out of2478', 'system accuracy': 83.61581920903954, 'expert accuracy': 83.45617662111576, 'classifier accuracy': 94.44418209949416, 'alone classifier': 0.0}\n",
      "{'coverage': '104 out of2478', 'system accuracy': 83.97901533494753, 'expert accuracy': 83.57202328795086, 'classifier accuracy': 93.26914108736433, 'alone classifier': 0.0}\n",
      "{'coverage': '104 out of2478', 'system accuracy': 83.97901533494753, 'expert accuracy': 83.57202328795086, 'classifier accuracy': 93.26914108736433, 'alone classifier': 0.0}\n",
      "[4.196933010492333, 83.97901533494753, 83.57202328795086, 93.26914108736433]\n",
      "{'coverage': '0 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.41403685116732, 'classifier accuracy': 0.0, 'alone classifier': 0.0}\n",
      "{'coverage': '12 out of2478', 'system accuracy': 83.53510895883777, 'expert accuracy': 83.45498106610049, 'classifier accuracy': 99.99916667361106, 'alone classifier': 0.0}\n",
      "{'coverage': '3 out of2478', 'system accuracy': 83.4140435835351, 'expert accuracy': 83.39393265503574, 'classifier accuracy': 99.99666677777407, 'alone classifier': 0.0}\n",
      "{'coverage': '41 out of2478', 'system accuracy': 83.69652945924132, 'expert accuracy': 83.58636983287896, 'classifier accuracy': 90.24368233248211, 'alone classifier': 0.0}\n",
      "{'coverage': '248 out of2478', 'system accuracy': 84.86682808716706, 'expert accuracy': 83.7668086307795, 'classifier accuracy': 94.75802630724746, 'alone classifier': 0.0}\n",
      "{'coverage': '248 out of2478', 'system accuracy': 84.86682808716706, 'expert accuracy': 83.7668086307795, 'classifier accuracy': 94.75802630724746, 'alone classifier': 0.0}\n",
      "[10.008071025020177, 84.86682808716706, 83.7668086307795, 94.75802630724746]\n",
      "{'coverage': '1222 out of2478', 'system accuracy': 88.86198547215497, 'expert accuracy': 85.03183359365707, 'classifier accuracy': 92.79868307703084, 'alone classifier': 0.0}\n",
      "{'coverage': '1579 out of2478', 'system accuracy': 92.13075060532688, 'expert accuracy': 86.42934673429438, 'classifier accuracy': 95.37681473231066, 'alone classifier': 0.0}\n",
      "{'coverage': '1731 out of2478', 'system accuracy': 91.64648910411623, 'expert accuracy': 85.14053945367084, 'classifier accuracy': 94.45406733367606, 'alone classifier': 0.0}\n",
      "{'coverage': '1288 out of2478', 'system accuracy': 90.23405972558515, 'expert accuracy': 84.53780091801666, 'classifier accuracy': 95.49688699558331, 'alone classifier': 0.0}\n",
      "{'coverage': '1082 out of2478', 'system accuracy': 89.50766747376917, 'expert accuracy': 84.02577592753927, 'classifier accuracy': 96.58039772824421, 'alone classifier': 0.0}\n",
      "{'coverage': '1579 out of2478', 'system accuracy': 92.13075060532688, 'expert accuracy': 86.42934673429438, 'classifier accuracy': 95.37681473231066, 'alone classifier': 0.0}\n",
      "[63.720742534301856, 92.13075060532688, 86.42934673429438, 95.37681473231066]\n"
     ]
    }
   ],
   "source": [
    "import copy, time \n",
    "for i in range(0,11):\n",
    "    model = CNN_rej(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 3, DROPOUT, PAD_IDX)\n",
    "\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "    alpha = i/10\n",
    "    N_EPOCHS = 5\n",
    "\n",
    "    best_valid_loss = 0\n",
    "    best_model = None\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc = train_reject(model, train_iterator, optimizer, alpha)\n",
    "        #train_loss, train_acc = train_reject_bla(model, train_iterator, optimizer)\n",
    "\n",
    "        #valid_loss, valid_acc = evaluate_reject(model, valid_iterator)\n",
    "        #print( metrics_print(model,test_iterator))\n",
    "        valid_loss = metrics_print(model,valid_iterator)[1]\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss >= best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "    \n",
    "\n",
    "    print(metrics_print(best_model, valid_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3222890595514881, 0.6363630578517656, 0.3140739983002775]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print_fairness(best_model, test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': '4820 out of7435', 'system accuracy': 92.03765971755212, 'expert accuracy': 85.77437202490462, 'classifier accuracy': 95.43568266730948, 'alone classifier': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[64.8285137861466, 92.03765971755212, 85.77437202490462, 95.43568266730948]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print(best_model, test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gL9zMseKV08"
   },
   "source": [
    "# Baseline: Confidence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTpVIBmaTd0F"
   },
   "outputs": [],
   "source": [
    "class CNN_(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        \n",
    "        out = self.fc(cat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4DW24ej8Kiog"
   },
   "source": [
    "## expert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wa26cku4KXn_"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 300\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 2\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model_expert = CNN_(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 2, DROPOUT, PAD_IDX)\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model_expert.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model_expert.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model_expert.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xI84VYA_Kovo"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model_expert.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_expert = model_expert.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpLZVhleKrd6"
   },
   "outputs": [],
   "source": [
    "def train_expert(model_exp, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model_exp.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model_exp(batch.text)\n",
    "\n",
    "        \n",
    "        loss = criterion(predictions, batch.expert)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.expert)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate_expert(model_exp, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model_exp.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model_exp(batch.text)\n",
    "            loss = criterion(predictions, batch.expert)\n",
    "            acc = categorical_accuracy(predictions, batch.expert)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "colab_type": "code",
    "id": "I0P9v_fnKu8x",
    "outputId": "bc853ec7-c1b7-4430-d138-d4ed12771bd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.460 | Train Acc: 84.05%\n",
      "\t Val. Loss: 0.457 |  Val. Acc: 83.28%\n",
      "Epoch: 02 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.416 | Train Acc: 84.42%\n",
      "\t Val. Loss: 0.470 |  Val. Acc: 83.40%\n",
      "Epoch: 03 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.357 | Train Acc: 85.53%\n",
      "\t Val. Loss: 0.479 |  Val. Acc: 82.64%\n",
      "Epoch: 04 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.292 | Train Acc: 88.09%\n",
      "\t Val. Loss: 0.538 |  Val. Acc: 78.81%\n",
      "Epoch: 05 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.221 | Train Acc: 91.23%\n",
      "\t Val. Loss: 0.621 |  Val. Acc: 81.01%\n",
      "Epoch: 06 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.154 | Train Acc: 94.25%\n",
      "\t Val. Loss: 0.683 |  Val. Acc: 79.05%\n",
      "Epoch: 07 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.121 | Train Acc: 95.59%\n",
      "\t Val. Loss: 0.802 |  Val. Acc: 79.75%\n",
      "Epoch: 08 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.095 | Train Acc: 96.90%\n",
      "\t Val. Loss: 0.877 |  Val. Acc: 78.71%\n",
      "Epoch: 09 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.080 | Train Acc: 97.42%\n",
      "\t Val. Loss: 0.997 |  Val. Acc: 77.19%\n",
      "Epoch: 10 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.066 | Train Acc: 97.81%\n",
      "\t Val. Loss: 1.078 |  Val. Acc: 78.10%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train_expert(model_expert, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate_expert(model_expert, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_expert.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2UHAGm-QW-I"
   },
   "source": [
    "## classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "meGJ9JJXQKMo"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 300\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 3\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model_class = CNN_(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model_class.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model_class.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model_class.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model_class.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_class = model_class.to(device)\n",
    "criterion = criterion.to(device)\n",
    "def train(model_class, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model_class.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model_class(batch.text)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "def evaluate(model_class, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model_class.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            predictions = model_class(batch.text)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = categorical_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "vDJ68oaoQi3v",
    "outputId": "56617497-e5ef-4955-bf1d-f00109752210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.449 | Train Acc: 83.68%\n",
      "\t Val. Loss: 0.339 |  Val. Acc: 87.94%\n",
      "Epoch: 02 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.272 | Train Acc: 90.47%\n",
      "\t Val. Loss: 0.319 |  Val. Acc: 88.86%\n",
      "Epoch: 03 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.199 | Train Acc: 93.21%\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 88.98%\n",
      "Epoch: 04 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.145 | Train Acc: 94.85%\n",
      "\t Val. Loss: 0.372 |  Val. Acc: 88.84%\n",
      "Epoch: 05 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.101 | Train Acc: 96.55%\n",
      "\t Val. Loss: 0.374 |  Val. Acc: 89.34%\n",
      "Epoch: 06 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.065 | Train Acc: 97.94%\n",
      "\t Val. Loss: 0.408 |  Val. Acc: 88.83%\n",
      "Epoch: 07 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.052 | Train Acc: 98.52%\n",
      "\t Val. Loss: 0.441 |  Val. Acc: 88.49%\n",
      "Epoch: 08 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.040 | Train Acc: 98.80%\n",
      "\t Val. Loss: 0.505 |  Val. Acc: 88.43%\n",
      "Epoch: 09 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.032 | Train Acc: 99.13%\n",
      "\t Val. Loss: 0.528 |  Val. Acc: 88.60%\n",
      "Epoch: 10 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.025 | Train Acc: 99.18%\n",
      "\t Val. Loss: 0.566 |  Val. Acc: 88.82%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model_class, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model_class, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_class.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VtNZ4bMAT2_8"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "def metrics_print_confid(net_class, net_exp, loader):\n",
    "    net_class.eval()\n",
    "    net_exp.eval()\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            outputs_exp = net_exp(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                r_score = 1 - np.max(arr) #outputs_class.data[i][predicted[i].item()].item()\n",
    "                arr_exp = [outputs_exp.data[i][0].item(),outputs_exp.data[i][1].item()]\n",
    "                arr_exp = softmax(arr_exp)\n",
    "                r_score = r_score - arr_exp[1]\n",
    "                r = 0\n",
    "                if r_score >= 0:\n",
    "                    r = 1\n",
    "                if r==0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == data.label[i]).item()\n",
    "                    correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                if r==1:\n",
    "                    exp += 1 - data.expert[i].item()\n",
    "                    correct_sys += 1 - data.expert[i].item()\n",
    "                    exp_total+=1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    print(to_print)\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "\n",
    "def metrics_print_confid_fairness(net_class, net_exp, loader):\n",
    "    net_class.eval()\n",
    "    net_exp.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            outputs_exp = net_exp(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                r_score = 1 - np.max(arr) #outputs_class.data[i][predicted[i].item()].item()\n",
    "                arr_exp = [outputs_exp.data[i][0].item(),outputs_exp.data[i][1].item()]\n",
    "                arr_exp = softmax(arr_exp)\n",
    "                r_score = r_score - arr_exp[1]\n",
    "                r = 0\n",
    "                if r_score >= 0:\n",
    "                    r = 1\n",
    "                prediction = 0\n",
    "                if r==0:\n",
    "                    prediction = predicted[i]\n",
    "                if r==1:\n",
    "                    prediction = data.expertlabel[i].item()\n",
    "                    \n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "    print(group_1_counts)\n",
    "    print(group_0_counts)\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    print(to_print)\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "M5sUm1NgVZrY",
    "outputId": "8e1ea87e-49af-4068-d7d7-9b73c98ef791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': '4766 out of7435', 'system accuracy': 91.44586415601883, 'expert accuracy': 86.0621891298472, 'classifier accuracy': 94.46076176120935, 'alone classifier': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[64.10221923335575, 91.44586415601883, 86.0621891298472, 94.46076176120935]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print_confid(model_class, model_expert,test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "332\n",
      "{'group0': 0.3162649649804323, 'group1': 0.572726752066589, 'discrimination': -0.2564617870861567}\n",
      "[0.3162649649804323, 0.572726752066589, 0.2564617870861567]\n"
     ]
    }
   ],
   "source": [
    "print(metrics_print_confid_fairness(model_class, model_expert,test_iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YzzfbXZ6aJH"
   },
   "source": [
    "# Oracle Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJf-zDG46cbU"
   },
   "outputs": [],
   "source": [
    "def metrics_print_oracle(net_class, loader):\n",
    "    # prints classification metrics for Oracle baseline\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = 0\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                #r = (data.group[i].item() == 0)\n",
    "                if data.group[i].item() == 0:\n",
    "                    if np.max(arr) <= 0.90:\n",
    "                        r = 1\n",
    "                else:\n",
    "                    if np.max(arr) <= 0.75:\n",
    "                        r = 1\n",
    "                if r==0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == data.label[i]).item()\n",
    "                    correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                if r==1:\n",
    "                    exp += 1 - data.expert[i].item()\n",
    "                    correct_sys += 1 - data.expert[i].item()\n",
    "                    exp_total+=1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    print(to_print)\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "def metrics_print_oracle_fairness(net_class, loader):\n",
    "    net_class.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = 0\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                #r = (data.group[i].item() == 0)\n",
    "                if data.group[i].item() == 0:\n",
    "                    if np.max(arr) <= 0.90:\n",
    "                        r = 1\n",
    "                else:\n",
    "                    if np.max(arr) <= 0.75:\n",
    "                        r = 1                \n",
    "                if r==0:\n",
    "                    prediction = predicted[i]\n",
    "                if r==1:\n",
    "                    prediction = data.expertlabel[i].item()\n",
    "                    \n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_print_classifier(net_class, loader):\n",
    "    # print classification metrics of the classifier alone on all the dataset\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                total += 1\n",
    "                correct += (predicted[i] == data.label[i]).item()\n",
    "                correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    print(to_print)\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "\n",
    "def metrics_print_classifier_fairness(net_class, loader):\n",
    "    # print fairness metrics of the classifier alone on all the dataset\n",
    "    net_class.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                prediction = predicted[i]\n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    print(to_print)\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def metrics_print_expert_fairness( loader):\n",
    "    # print fairness metrics of the expert on all the dataset\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            batch_size =len(data)            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                prediction = data.expertlabel[i].item()\n",
    "                    \n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    print(to_print)\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group0': 0.07831322942372608, 'group1': 0.11818171074389933, 'discrimination': -0.039868481320173246}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07831322942372608, 0.11818171074389933, 0.039868481320173246]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print_expert_fairness( test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group0': 0.7108431593845906, 'group1': 0.881817380166018, 'discrimination': -0.17097422078142732}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7108431593845906, 0.881817380166018, 0.17097422078142732]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print_classifier_fairness(model_class, test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "h0QDnycBFWWB",
    "outputId": "d411364e-ec6e-4a89-bf79-8eedc5e4673a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': '6714 out of7435', 'system accuracy': 91.31136516476127, 'expert accuracy': 86.40774302143052, 'classifier accuracy': 91.83794918322982, 'alone classifier': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[90.30262273032952, 91.31136516476127, 86.40774302143052, 91.83794918322982]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print_oracle(model_class,test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5512046532516105, 0.7999992727279338, 0.2487946194763233]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_print_oracle_fairness(model_class,test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: repeat data building for each expert type\n",
    "the following repeats the above code many times to obtain error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@Fulf_ShawnFulf', 'peckerwood']\n",
      "['GA', 'Charlie', '@Charlie4927', '@sholzbee', '@DorisTafoya1', '@cat_lmbo', '@Jagauress', '@Walter_lars', '@lynnemrnp', '@AmyMek', '@Justin_Awe']\n",
      "['RT', '@cenopant', ':', '(', 'she)s', '\\n', 'bro(was)ken', '\\n', 'bec(a)use', '\\n', 's(side)he', '\\n', 'beli(hoe)ved']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# build expert data\n",
    "all_data = train_data_orig[0]\n",
    "p = 0.75 # expert probability of being correct for AA tweeet\n",
    "q = 0.9 # expert probability of being correct for AA tweeet\n",
    "sum = 0\n",
    "total = 0\n",
    "i = 0\n",
    "aa_frac = 0\n",
    "for example in all_data:\n",
    "    lang = predict_lang(vars(example)['text'])\n",
    "    aa = 0\n",
    "    try:\n",
    "        if lang[0] >= 0.5:\n",
    "            aa = 1\n",
    "    except:\n",
    "        print(vars(example)['text'])\n",
    "    label = vars(example)['label']\n",
    "    exp = 0 # 0: expert wrong, 1: expert is right\n",
    "    exp_label = 0\n",
    "    if aa == 1: # if tweet is african american\n",
    "        #if label == '2':\n",
    "        #    exp = 0 # never predict neither\n",
    "        #else:\n",
    "        coin = np.random.binomial(1,p) \n",
    "        if coin:\n",
    "            exp =1 # is right 90% of time\n",
    "            exp_label = np.longlong(label)\n",
    "        else:\n",
    "            exp_label = np.longlong(np.argmax(np.random.multinomial(1,[1/3]*3 , size=1)))\n",
    "            exp =0\n",
    "    else:\n",
    "        coin = np.random.binomial(1,q)\n",
    "        if coin:\n",
    "            exp =1 # is right 90% of time\n",
    "            exp_label = np.longlong(label)\n",
    "        else:\n",
    "            exp_label = np.longlong(np.argmax(np.random.multinomial(1,[1/3]*3 , size=1)))\n",
    "            exp =0\n",
    "    #if label =='2' : # 2: neither, 1: offensive, 0: hate speech\n",
    "    #    aa = 1\n",
    "    vars(all_data[i])['expertlabel'] = exp_label\n",
    "    vars(all_data[i])['group'] = str(aa)\n",
    "    vars(all_data[i])['expert'] = exp\n",
    "    aa_frac += aa\n",
    "    i += 1\n",
    "    total +=1\n",
    "    sum += exp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, valid_data  = all_data.split(split_ratio=[0.7,0.2,0.1])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    sort = False,\n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to be changed for each expert model\n",
    "def metrics_print_oracle(net_class, loader):\n",
    "    correct = 0\n",
    "    correct_sys = 0\n",
    "    exp = 0\n",
    "    exp_total = 0\n",
    "    total = 0\n",
    "    real_total = 0\n",
    "    alone_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = 0\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                #r = (data.group[i].item() == 0)\n",
    "                if data.group[i].item() == 0:\n",
    "                    if np.max(arr) <= q:\n",
    "                        r = 1\n",
    "                else:\n",
    "                    if np.max(arr) <= p:\n",
    "                        r = 1\n",
    "                if r==0:\n",
    "                    total += 1\n",
    "                    correct += (predicted[i] == data.label[i]).item()\n",
    "                    correct_sys += (predicted[i] == data.label[i]).item()\n",
    "                if r==1:\n",
    "                    exp += 1 - data.expert[i].item()\n",
    "                    correct_sys += 1 - data.expert[i].item()\n",
    "                    exp_total+=1\n",
    "                real_total += 1\n",
    "    cov = str(total) + str(\" out of\") + str(real_total)\n",
    "    to_print={\"coverage\":cov, \"system accuracy\": 100*correct_sys/real_total, \"expert accuracy\":100* exp/(exp_total+0.0002),\"classifier accuracy\":100*correct/(total+0.0001), \"alone classifier\": 100*alone_correct/real_total }\n",
    "    return [100*total/real_total,  100*correct_sys/real_total, 100* exp/(exp_total+0.0002),100*correct/(total+0.0001) ]\n",
    "\n",
    "def metrics_print_oracle_fairness(net_class, loader):\n",
    "    net_class.eval()\n",
    "    group_1 = 0\n",
    "    group_1_counts = 0\n",
    "    group_0 = 0\n",
    "    group_0_counts = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            outputs_class = net_class(data.text)\n",
    "            _, predicted = torch.max(outputs_class.data, 1)\n",
    "            batch_size = outputs_class.size()[0]            # batch_size\n",
    "            for i in range(0,batch_size):\n",
    "                r = 0\n",
    "                arr = [outputs_class.data[i][0].item(),outputs_class.data[i][1].item(),outputs_class.data[i][2].item()]\n",
    "                arr = softmax(arr)\n",
    "                #r = (data.group[i].item() == 0)\n",
    "                if data.group[i].item() == 0:\n",
    "                    if np.max(arr) <= q:\n",
    "                        r = 1\n",
    "                else:\n",
    "                    if np.max(arr) <= p:\n",
    "                        r = 1                \n",
    "                \n",
    "                if r==0:\n",
    "                    prediction = predicted[i]\n",
    "                if r==1:\n",
    "                    prediction = data.expertlabel[i].item()\n",
    "                    \n",
    "                if  data.group[i].item() == 0:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_0_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_0 += 1\n",
    "                else:\n",
    "                    if data.label[i].item() == 2:\n",
    "                        group_1_counts += 1\n",
    "                        if prediction == 1 or prediction ==0:\n",
    "                            group_1 += 1\n",
    "\n",
    "    to_print={\"group0\":group_0/(group_0_counts+0.0001), \"group1\": group_1/(group_1_counts+0.0001), \"discrimination\":group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001) }\n",
    "    return [group_0/(group_0_counts+0.0001), group_1/(group_1_counts+0.0001), abs(group_0/(group_0_counts+0.0001)- group_1/(group_1_counts+0.0001))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n",
      "{'coverage': '4906 out of7435', 'system accuracy': 93.49024882313383, 'expert accuracy': 88.41438604868438, 'classifier accuracy': 96.1068060312514, 'alone classifier': 0.0}\n",
      "110\n",
      "332\n",
      "{'group0': 0.21385535727248275, 'group1': 0.618181256198858, 'discrimination': -0.40432589892637527}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michel.sh/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': '1567 out of2478', 'system accuracy': 91.76755447941889, 'expert accuracy': 86.3885650079989, 'classifier accuracy': 94.89469719880682, 'alone classifier': 0.0}\n",
      "{'coverage': '1744 out of2478', 'system accuracy': 92.25181598062954, 'expert accuracy': 86.78471749735219, 'classifier accuracy': 94.55274687197553, 'alone classifier': 0.0}\n",
      "{'coverage': '1003 out of2478', 'system accuracy': 88.05488297013721, 'expert accuracy': 84.06778521114776, 'classifier accuracy': 93.91823590047498, 'alone classifier': 0.0}\n",
      "{'coverage': '1243 out of2478', 'system accuracy': 91.04116222760291, 'expert accuracy': 85.7489739677775, 'classifier accuracy': 96.29926819796717, 'alone classifier': 0.0}\n",
      "{'coverage': '715 out of2478', 'system accuracy': 87.32849071832122, 'expert accuracy': 84.17469266310917, 'classifier accuracy': 95.10488180351304, 'alone classifier': 0.0}\n",
      "{'coverage': '1682 out of2478', 'system accuracy': 90.79903147699758, 'expert accuracy': 84.4220893411836, 'classifier accuracy': 93.81687908341979, 'alone classifier': 0.0}\n",
      "{'coverage': '1060 out of2478', 'system accuracy': 89.30589184826474, 'expert accuracy': 84.55570034475313, 'classifier accuracy': 95.66036833392752, 'alone classifier': 0.0}\n",
      "{'coverage': '1434 out of2478', 'system accuracy': 91.60613397901534, 'expert accuracy': 86.0153091924695, 'classifier accuracy': 95.67642289564694, 'alone classifier': 0.0}\n",
      "{'coverage': '1612 out of2478', 'system accuracy': 91.56577885391445, 'expert accuracy': 85.91222034359808, 'classifier accuracy': 94.60297179882309, 'alone classifier': 0.0}\n",
      "{'coverage': '1313 out of2478', 'system accuracy': 90.27441485068604, 'expert accuracy': 85.2360368693499, 'classifier accuracy': 94.74485188538829, 'alone classifier': 0.0}\n",
      "{'coverage': '1546 out of2478', 'system accuracy': 91.52542372881356, 'expert accuracy': 86.05148367993912, 'classifier accuracy': 94.8253496231986, 'alone classifier': 0.0}\n",
      "{'coverage': '1637 out of2478', 'system accuracy': 91.96933010492333, 'expert accuracy': 87.0392183022073, 'classifier accuracy': 94.50213228453681, 'alone classifier': 0.0}\n",
      "{'coverage': '1147 out of2478', 'system accuracy': 88.70056497175142, 'expert accuracy': 84.59803386956666, 'classifier accuracy': 93.46119499030559, 'alone classifier': 0.0}\n",
      "{'coverage': '770 out of2478', 'system accuracy': 88.17594834543988, 'expert accuracy': 84.6604116322703, 'classifier accuracy': 95.97401350986839, 'alone classifier': 0.0}\n",
      "{'coverage': '1142 out of2478', 'system accuracy': 89.95157384987894, 'expert accuracy': 84.50597537335699, 'classifier accuracy': 96.32223324673964, 'alone classifier': 0.0}\n",
      "Our method\n",
      "{'coverage': '5318 out of7435', 'system accuracy': 92.99260255548083, 'expert accuracy': 88.04911780357885, 'classifier accuracy': 94.96050968483434, 'alone classifier': 0.0}\n",
      "[71.52656355077337, 92.99260255548083, 88.04911780357885, 94.96050968483434]\n",
      "[83.53732347007397, 93.35574983187627, 90.11436436039799, 93.99452432789366]\n"
     ]
    }
   ],
   "source": [
    "exp_conf = []\n",
    "exp_rej = []\n",
    "exp_ora = []\n",
    "exp_conf_fairness = []\n",
    "exp_rej_fairness = []\n",
    "exp_ora_fairness = []\n",
    "max_trials = 1\n",
    "for exp in range(0,max_trials):\n",
    "    train_data, test_data, valid_data  = all_data.split(split_ratio=[0.6,0.1,0.3])\n",
    "\n",
    "    BATCH_SIZE = 64\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "        (train_data, valid_data, test_data), \n",
    "        sort = False,\n",
    "        batch_size = BATCH_SIZE, \n",
    "        device = device)\n",
    "    ##################################################################################################\n",
    "    ##################################################################################################\n",
    "    # baseline confidence\n",
    "    ##################################################################################################\n",
    "    INPUT_DIM = len(TEXT.vocab)\n",
    "    EMBEDDING_DIM = 100\n",
    "    N_FILTERS = 300\n",
    "    FILTER_SIZES = [3,4,5]\n",
    "    OUTPUT_DIM = 2\n",
    "    DROPOUT = 0.5\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "    model_expert = CNN_(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 2, DROPOUT, PAD_IDX)\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    model_expert.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "    model_expert.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model_expert.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    optimizer = optim.Adam(model_expert.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model_expert = model_expert.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    N_EPOCHS = 5\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train_expert(model_expert, train_iterator, optimizer, criterion)\n",
    "        #valid_loss, valid_acc = evaluate_expert(model_expert, valid_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # classifier\n",
    "    INPUT_DIM = len(TEXT.vocab)\n",
    "    EMBEDDING_DIM = 100\n",
    "    N_FILTERS = 300\n",
    "    FILTER_SIZES = [3,4,5]\n",
    "    OUTPUT_DIM = 3\n",
    "    DROPOUT = 0.5\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "    model_class = CNN_(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    model_class.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "    model_class.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model_class.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "    optimizer = optim.Adam(model_class.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model_class = model_class.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    N_EPOCHS = 5\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train(model_class, train_iterator, optimizer, criterion)\n",
    "        #valid_loss, valid_acc = evaluate(model_class, valid_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    ####################################\n",
    "    print(\"Baseline\")\n",
    "    \n",
    "    conf = metrics_print_confid(model_class, model_expert,test_iterator)\n",
    "    exp_conf.append(conf)\n",
    "    conf = metrics_print_confid_fairness(model_class, model_expert,test_iterator)\n",
    "    exp_conf_fairness.append(conf)\n",
    "    ##################################################################################################\n",
    "    # my method \n",
    "    ##################################################################################################\n",
    "    INPUT_DIM = len(TEXT.vocab)\n",
    "    EMBEDDING_DIM = 100\n",
    "    N_FILTERS = 1000\n",
    "    FILTER_SIZES = [3,4,5]\n",
    "    OUTPUT_DIM = 4\n",
    "    DROPOUT = 0.5\n",
    "    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "    model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, 4, DROPOUT, PAD_IDX)\n",
    "\n",
    "    pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    N_EPOCHS = 15\n",
    "\n",
    "    best_valid_loss = 0\n",
    "    best_model = None\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc = train_reject(model, train_iterator, optimizer, 1)\n",
    "        #train_loss, train_acc = train_reject_bla(model, train_iterator, optimizer)\n",
    "\n",
    "        #valid_loss, valid_acc = evaluate_reject(model, valid_iterator)\n",
    "        valid_loss = metrics_print(model,valid_iterator)[1]\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss >= best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "    \n",
    "    print(\"Our method\")\n",
    "    rej = metrics_print(best_model, test_iterator)\n",
    "    exp_rej.append(rej)\n",
    "    print(rej)\n",
    "    rej = metrics_print_fairness(best_model, test_iterator)\n",
    "    exp_rej_fairness.append(rej)\n",
    "    ##############################################################################################\n",
    "    # ORACLE\n",
    "    ora = metrics_print_oracle(model_class, test_iterator)\n",
    "    print(ora)\n",
    "    exp_ora.append(ora)\n",
    "    ora = metrics_print_oracle_fairness(model_class, test_iterator)\n",
    "    exp_ora_fairness.append(ora)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_class = [\"coverage\", \"system accuracy\", \"expert accuracy\", \"classifier accuracy\"]\n",
    "metrics_fairness = [\"FPR for group 0\", \"FPR for group 1\", \"discrimination\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Confidence Baseline\n",
      "----\n",
      "For coverage\n",
      "average: 65.98520511096167\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "----\n",
      "For system accuracy\n",
      "average: 93.49024882313383\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "----\n",
      "For expert accuracy\n",
      "average: 88.41438604868438\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "----\n",
      "For classifier accuracy\n",
      "average: 96.1068060312514\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "#############################\n",
      "-----\n",
      "For FPR for group 0\n",
      "average: 0.21385535727248275\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "-----\n",
      "For FPR for group 1\n",
      "average: 0.618181256198858\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "-----\n",
      "For discrimination\n",
      "average: 0.40432589892637527\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michel.sh/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/michel.sh/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for Confidence Baseline\")\n",
    "for i in range(0,4):\n",
    "    print(\"----\")\n",
    "    print(\"For \" + metrics_class[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_conf[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n",
    "print(\"#############################\")\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(\"-----\")\n",
    "    print(\"For \" + metrics_fairness[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_conf_fairness[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Oracle Baseline\n",
      "----\n",
      "For coverage\n",
      "average: 83.53732347007397\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "----\n",
      "For system accuracy\n",
      "average: 93.35574983187627\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "----\n",
      "For expert accuracy\n",
      "average: 90.11436436039799\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "----\n",
      "For classifier accuracy\n",
      "average: 93.99452432789366\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "#############################\n",
      "-----\n",
      "For FPR for group 0\n",
      "average: 0.39759024168968626\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "-----\n",
      "For FPR for group 1\n",
      "average: 0.8545446776866567\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "-----\n",
      "For discrimination\n",
      "average: 0.4569544359969704\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for Oracle Baseline\")\n",
    "for i in range(0,4):\n",
    "    print(\"----\")\n",
    "    print(\"For \" + metrics_class[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_ora[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n",
    "print(\"#############################\")\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(\"-----\")\n",
    "    print(\"For \" + metrics_fairness[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_ora_fairness[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for our method L_{CE}\n",
      "----\n",
      "For coverage\n",
      "average: 71.52656355077337\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "----\n",
      "For system accuracy\n",
      "average: 92.99260255548083\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "----\n",
      "For expert accuracy\n",
      "average: 88.04911780357885\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "----\n",
      "For classifier accuracy\n",
      "average: 94.96050968483434\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "#############################\n",
      "-----\n",
      "For FPR for group 0\n",
      "average: 0.33132520140807187\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "-----\n",
      "For FPR for group 1\n",
      "average: 0.7909083719014801\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n",
      "-----\n",
      "For discrimination\n",
      "average: 0.45958317049340824\n",
      "std: 0.0\n",
      "95 confidence interval: (nan, nan)\n"
     ]
    }
   ],
   "source": [
    "print(\"Results for our method L_{CE}\")\n",
    "\n",
    "for i in range(0,4):\n",
    "    print(\"----\")\n",
    "    print(\"For \" + metrics_class[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_rej[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n",
    "print(\"#############################\")\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(\"-----\")\n",
    "    print(\"For \" + metrics_fairness[i])\n",
    "    arr = [0] * max_trials\n",
    "    for j in range(0,max_trials):\n",
    "        arr[j] = exp_rej_fairness[j][i]\n",
    "    print(\"average: \" +str(np.average(arr)))\n",
    "    print(\"std: \" + str(np.std(arr)))\n",
    "    print(\"95 confidence interval: \" + str(st.t.interval(0.95, len(arr)-1, loc=np.mean(arr), scale=st.sem(arr))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hatespeech - Faster Sentiment Analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
